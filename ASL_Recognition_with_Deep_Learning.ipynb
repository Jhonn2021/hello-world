{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL-Recognition-with-Deep-Learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfNUastGbT3TPRmiFYwCMe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhonn2021/hello-world/blob/master/ASL_Recognition_with_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgqT9pAmBFOP"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from keras.utils import np_utils, to_categorical\n",
        "from keras.preprocessing import image\n",
        "from os import listdir\n",
        "from os.path import isdir, join\n",
        "#from google.colab import files\n",
        "#files.upload()\n",
        "\n",
        "def load_data(container_path='datasets', folders=['A', 'B', 'C'],\n",
        "              size=2000, test_split=0.2, seed=0):\n",
        "    \"\"\"\n",
        "    Loads sign language dataset.\n",
        "    \"\"\"\n",
        "    \n",
        "    filenames, labels = [], []\n",
        "\n",
        "    for label, folder in enumerate(folders):\n",
        "        folder_path = join(container_path, folder)\n",
        "        images = [join(folder_path, d)\n",
        "                     for d in sorted(listdir(folder_path))]\n",
        "        labels.extend(len(images) * [label])\n",
        "        filenames.extend(images)\n",
        "    \n",
        "    random.seed(seed)\n",
        "    data = list(zip(filenames, labels))\n",
        "    random.shuffle(data)\n",
        "    data = data[:size]\n",
        "    filenames, labels = zip(*data)\n",
        "    \n",
        "    # Get the images\n",
        "    x = paths_to_tensor(filenames).astype('float32')/255\n",
        "    # Store the one-hot targets\n",
        "    y = np.array(labels)\n",
        "\n",
        "    x_train = np.array(x[:int(len(x) * (1 - test_split))])\n",
        "    y_train = np.array(y[:int(len(x) * (1 - test_split))])\n",
        "    x_test = np.array(x[int(len(x) * (1 - test_split)):])\n",
        "    y_test = np.array(y[int(len(x) * (1 - test_split)):])\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "\n",
        "def path_to_tensor(img_path, size):\n",
        "    # loads RGB image as PIL.Image.Image type\n",
        "    img = image.load_img(img_path, target_size=(size, size))\n",
        "    # convert PIL.Image.Image type to 3D tensor\n",
        "    x = image.img_to_array(img)\n",
        "    # convert 3D tensor to 4D tensor \n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "\n",
        "def paths_to_tensor(img_paths, size=50):\n",
        "    list_of_tensors = [path_to_tensor(img_path, size) for img_path in img_paths]\n",
        "    return np.vstack(list_of_tensors)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}